# HGTN
**abstract**
Graph neural network has been widely used in the representation and learning of graph structure and achieved excellent performance in tasks such as node classification and link prediction. However, the ubiquitous heterogeneous graph network in the real world is laborious to model with pairwise relationships; otherwise, the information in the learning task will be incomplete. Meanwhile, the incomplete expression of semantic information in heterogeneous networks also seriously hinders the expression of node information. An end-to-end hypergraph transformer neural network (HGTN) is proposed, which uses the communication ability between hyperedge nodes to learn high-order relationships and discover semantic information between different types of nodes or edges. Specifically, the attention mechanism is used to learn the high-order semantic information hidden in the original heterogeneous hypergraph, generating a useful meta-path. The model develops a multi-scale attention mechanism to aggregate graph information and learn the implicit high-order topological information model. The proposed model is evaluated with node classification task on six datasets: DBLP, ACM, IBDM, CITE, REUT, and STUD. Experiments on a large number of benchmarks show the advantages of HGTN.
